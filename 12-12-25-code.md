# Fraud Detection Modules: Technical Documentation

This document explains the implementation and reasoning behind the two advanced fraud detection modules powered by LLMs (DSPy): `Geospatial Analysis` and `Text Consistency Analysis`.

---

## 1. Geospatial Analysis
**File**: [src/services/modules/fraud_detection/geospatial_analysis.py](file:///c:/Users/sudik/OneDrive/Desktop/Mindcres/ai-space/smart_seva/server/src/services/modules/fraud_detection/geospatial_analysis.py)

### 1.1 Reasoning
Legacy rule-based systems struggle with geospatial validation because:
1.  **Complex Hierarchies**: States, Districts, Mandals, and Tehsils have complex, nested relationships that are hard to maintain in static lists.
2.  **Cross-Border Validity**: Some authorities (e.g., Central Departments in a capital city) have jurisdiction over the entire state, which simple "District Match" rules would flag as fraud.
3.  **Ambiguity**: OCR often returns partial addresses.

**Why LLM?**
Large Language Models have internalized knowledge of geography and administrative structures. They can determine strict vs. plausible jurisdiction better than a static database.

### 1.2 Code Explanation

#### [GeospatialCheck](file:///c:/Users/sudik/OneDrive/Desktop/Mindcres/ai-space/smart_seva/server/src/services/modules/fraud_detection/geospatial_analysis.py#20-38) (DSPy Signature)
Defines the "Prompt" sent to the LLM. It enforces granular checking:
*   **Administrative Hierarchy**: Explicitly asks *Does this Mandal belong to this District?*
*   **Distance Plausibility**: Checks if it's feasible for the applicant to visit the issuer.
*   **Structured Output**: Returns `match_level` (State/District/Local) and `risk_score`.

```python
class GeospatialCheck(dspy.Signature):
    ...
    match_level = dspy.OutputField(desc="Level of match: 'Strict Local', 'District', 'State', or 'Mismatch'")
    distance_plausibility = dspy.OutputField(desc="Is the physical distance plausible for this service?")
    ...
```

#### `GeospatialAnalyzer.analyze`
1.  **Field Extraction**: Scans the input dictionary for keywords like "address" and "authority" to find the relevant strings.
2.  **LLM Call**: Invokes the [GeospatialCheck](file:///c:/Users/sudik/OneDrive/Desktop/Mindcres/ai-space/smart_seva/server/src/services/modules/fraud_detection/geospatial_analysis.py#20-38) signature.
3.  **Risk Logic**:
    *   If `is_consistent` is `False` OR `risk_score > 60`, it flags a **Mismatch**.
    *   The [score](file:///c:/Users/sudik/OneDrive/Desktop/Mindcres/ai-space/smart_seva/server/src/services/modules/fraud_detection/error_level_analysis.py#272-407) returned is an *Inverse Risk Score* (for overall calculation) or the raw risk depending on the aggregator logic.

---

## 2. Text Consistency Analysis
**File**: [src/services/modules/fraud_detection/text_consistency_analysis.py](file:///c:/Users/sudik/OneDrive/Desktop/Mindcres/ai-space/smart_seva/server/src/services/modules/fraud_detection/text_consistency_analysis.py)

### 2.1 Reasoning
Forgery often leaves linguistic traces that are invisible to standard OCR but obvious to an intelligent reader:
1.  **Grammar Errors**: Official templates rarely have bad grammar; forged inserts often do.
2.  **Tone Shifts**: Mixing formal "Officialese" with casual conversational styles.
3.  **Formatting**: Inconsistent capitalization (e.g., "hyderabad" vs "Hyderabad") often indicates cut-and-paste jobs.

**Why LLM?**
A simple spellchecker would flag OCR artifacts (e.g., `Nam3` instead of `Name`) as errors. An LLM contextually understands that `Nam3` is an **OCR error** (ignore), while `I has certify` is a **Grammar error** (flag).

### 2.2 Code Explanation

#### [TextConsistencyCheck](file:///c:/Users/sudik/OneDrive/Desktop/Mindcres/ai-space/smart_seva/server/src/services/modules/fraud_detection/text_consistency_analysis.py#21-37) (DSPy Signature)
The Prompt includes a **CRITICAL INSTRUCTION** to distinguish OCR noise from actual linguistic anomalies.

```python
class TextConsistencyCheck(dspy.Signature):
    ...
    CRITICAL INSTRUCTION: Distinguish between simple OCR errors... and ACTUAL linguistic anomalies
    ...
    grammar_issues = dspy.OutputField(...)
    tone_consistency = dspy.OutputField(...)
```

#### `TextConsistencyAnalyzer.analyze`
1.  **Text Preparation**: Truncates text to ~3000 chars to fit context windows while capturing enough style.
2.  **LLM Call**: Invokes [TextConsistencyCheck](file:///c:/Users/sudik/OneDrive/Desktop/Mindcres/ai-space/smart_seva/server/src/services/modules/fraud_detection/text_consistency_analysis.py#21-37).
3.  **Parsing**:
    *   Extracts specific lists of `grammar_issues` and `formatting_issues`.
    *   Calculates a `consistency_score` (100 = Perfect).
4.  **Error Handling**: If the LLM fails (e.g., timeout), it "fails open" (Score 80) to avoid blocking valid users due to system errors.
